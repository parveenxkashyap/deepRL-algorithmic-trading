{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bda495",
   "metadata": {},
   "source": [
    "# Algorithmic Trading Using Deep Reinforcdment Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2a663",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "- [Introduction](#scrollTo=9SNR5Z82unXd)\n",
    "\n",
    "- [Import Dependencies](#scrollTo=012Sf4GHumaL)\n",
    "\n",
    "- [Data & Preprocessing](#scrollTo=fAq9RY7dtwTe)\n",
    "\n",
    "- [Custom Trading Environment Setting](#scrollTo=z-g6RJHLpuKh)\n",
    "\n",
    "- [Utility Functions](#scrollTo=jWElTzIctZ3E)\n",
    "\n",
    "- [PPO Agent](#scrollTo=rz1CA85UkXPI)\n",
    "\n",
    "  - [Agent setting](#scrollTo=bKxYFvx8nALx)\n",
    "\n",
    "  - [Training](#scrollTo=VXm3OnAlnF51)\n",
    "\n",
    "  - [Results and Validation](#scrollTo=3D6ypjL-nh8J)\n",
    "\n",
    "- [DQN Agent](#scrollTo=F1SfonB9kXPR)\n",
    "\n",
    "  - [Agent Setting](#scrollTo=hIqzHqzPn2Lv)\n",
    "\n",
    "  - [Training](#scrollTo=6tBBq8TQn7JZ)\n",
    "\n",
    "  - [Results and Validation](#scrollTo=SukTkoX8oExx)\n",
    "\n",
    "- [Visualization](#scrollTo=V48fsZn7jv9Q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900532b2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b19d7",
   "metadata": {},
   "source": [
    "In quantitative finance, stock trading is essentially a dynamic decision problem, that is, deciding where, at what price, and how much to trade in a highly stochastic, dynamic, and complex stock market. With recent advances in deep reinforcement learning (DRL) methods, sequential dynamic decision problems can be modeled and solved with a human-like approach.\n",
    "\n",
    "<br>\n",
    "\n",
    "In this poject, we examine the potential and performance of deep reinforcement learning to optimize stock trading strategies and thus maximize investment returns. Google stock is selected as our trading stock and the daily opening and closing price along with trading volume and several technical indicators are used as a training environment and trading market.\n",
    "\n",
    "<br>\n",
    "\n",
    "We present two trading agents based on deep reinforcement learning, one using Proximal Policy Otimization algorithm and the other based on Deep Q-Learing, to autonomously make trading decisions and generate returns in dynamic financial markets. The performance of these intelligent agents is compared with the performance of the buy and hold strategy. And at the end, it is shown that the proposed deep reinforcement learning approach performs better than the buy and hold benchmark in terms of risk assessment criteria and portfolio return.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**References:**\n",
    "* Human-level control through deep reinforcement learning (Deep Q-Learning) : [paper](https://www.nature.com/articles/nature14236)\n",
    "* Proximal Policy Optimization) : [paper](https://arxiv.org/abs/1707.06347), [blog](https://openai.com/blog/openai-baselines-ppo/), [spinning-up](https://spinningup.openai.com/en/latest/algorithms/ppo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcf1d7",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install talib-binary\n",
    "!pip install gym_anytrading\n",
    "!pip install quantstats\n",
    "!pip install stable_baselines3\n",
    "!pip install pyfolio\n",
    "!pip install --upgrade gym==0.25.2\n",
    "!pip install stable_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc973b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "from pandas_datareader import data as web\n",
    "import pandas_datareader as pdr\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import logging\n",
    "import datetime\n",
    "import pyfolio.timeseries as ts\n",
    "import scipy.stats as st\n",
    "\n",
    "from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions \n",
    "# from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import quantstats as qs\n",
    "\n",
    "from stable_baselines3 import A2C, DDPG, DQN, PPO, TD3, SAC\n",
    "# from stable_baselines import TRPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "# import torch\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "DECIMAL_SIGNS = 5\n",
    "rnd = lambda x: round(x, DECIMAL_SIGNS)\n",
    "\n",
    "#==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862522ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cd2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__main__ logger started.\n"
     ]
    }
   ],
   "source": [
    "#============\n",
    "logging.basicConfig()\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "log.info('%s logger started.', __name__)\n",
    "#============"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2545b8c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f767d",
   "metadata": {},
   "source": [
    "creating DataSource class to handle fetching data and calculating technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource(object):\n",
    "    def __init__(self, data_path, start_date, end_date,\n",
    "                    time_frame, tickers, window_size,\n",
    "                    # train_mode=True,\n",
    "                    # episode_duration=480,\n",
    "                    # train_split=0.8, normalize=True\n",
    "                    ):\n",
    "\n",
    "        self.tickers = tickers\n",
    "\n",
    "        if end_date == None:\n",
    "            end_date = datetime.datetime.now()\n",
    "        if start_date == None:\n",
    "            start_date = end_date - relativedelta(years=2)\n",
    "\n",
    "        self.data = pd.DataFrame()\n",
    "        for ticker in self.tickers:\n",
    "            csv_name = os.path.join(\n",
    "                            data_path,\n",
    "                            ticker+start_date.strftime('_from_%Y%m%d')+end_date.strftime('_to_%Y%m%d')+\".csv\"\n",
    "                            )\n",
    "            ticker_data = self._load_data(\n",
    "                                csv_name=csv_name, time_frame=time_frame,\n",
    "                                start_date=start_date, end_date=end_date, ticker=ticker\n",
    "                                )\n",
    "            self.data = pd.concat(\n",
    "                [self.data, ticker_data],\n",
    "                # join='inner'\n",
    "                )\n",
    "\n",
    "        self.date_time = self.data.index\n",
    "        self.count = self.data.shape[0]\n",
    "        self.window_size = window_size\n",
    "        self.states = self.data.values\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def seed(seed):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    \n",
    "    def _load_data(self, csv_name, time_frame, start_date, end_date,  ticker):\n",
    "        log.info('loading data for {}...'.format(ticker))\n",
    "\n",
    "        if os.path.exists(csv_name):\n",
    "            df = pd.read_csv(csv_name)\n",
    "        else:\n",
    "            with open(\"./tiingo_api_key.txt\") as file:\n",
    "                key = file.readline()\n",
    "            \n",
    "            # df = web.DataReader(ticker, time_frame,\n",
    "            #     start=start_date,\n",
    "            #     end=end_date,\n",
    "            #     api_key=key\n",
    "            #     ).dropna()\n",
    "            df = pdr.get_data_tiingo(ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                api_key=key\n",
    "                ).dropna()\n",
    "            \n",
    "            df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "            # print(df.columns)\n",
    "\n",
    "            df['ret_5'] = df.adjopen.pct_change(5)\n",
    "            df['ret_10'] = df.adjopen.pct_change(10)\n",
    "            df['ret_21'] = df.adjopen.pct_change(21)\n",
    "            df['rsi'] = talib.STOCHRSI(df.adjopen)[1]\n",
    "            df['macd'] = talib.MACD(df.adjopen)[1]\n",
    "            df['atr'] = talib.ATR(df.adjhigh, df.adjlow, df.adjopen)\n",
    "            df = df.replace((np.inf, -np.inf), np.nan).drop(['high', 'low','close','open','adjhigh', 'adjlow','divcash','splitfactor'], axis=1).dropna()\n",
    "            df.columns = [col+'_'+ticker for col in df.columns]\n",
    "            df.to_csv(csv_name,index_label=\"date_time\")\n",
    "            \n",
    "\n",
    "        log.info('got data for {}...'.format(ticker))\n",
    "        return df\n",
    "\n",
    "    def get_start_end_index(self,a,b):\n",
    "        \n",
    "        start_index = np.random.randint(a, b-20)\n",
    "        end_index = np.random.randint(start_index+10, b)\n",
    "    \n",
    "        return start_index, end_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047946dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            \"data\": {\n",
    "                \"time_frame\": \"tiingo\",\n",
    "                \"data_path\": os.path.join(os.getcwd(), \"data\"),\n",
    "                \"tickers\": [\"GOOG\",\"IBM\"],\n",
    "                \"episode_duration\": 480\n",
    "                },\n",
    "            \"seed\": 42,\n",
    "            \"model\": {\n",
    "                \"window_size\": 10,\n",
    "                \"initial_cash\": 1_000_000,\n",
    "                \"commission_rate\":0,\n",
    "                \"start_date\": datetime.datetime(2014,1,1),\n",
    "                \"end_date\": datetime.datetime(2022,8,1),\n",
    "                \"stat_save_folder\": None,\n",
    "                \"agent_save_folder\": None\n",
    "                 },\n",
    "            \"ddpg\": {\n",
    "                \"buffer_size\": 100000,\n",
    "                \"batch_size\": 64,\n",
    "                \"gamma\": 0.99,\n",
    "                \"tau\": 0.001,\n",
    "                \"learning_rate_actor\": 0.0001,\n",
    "                \"learning_rate_critic\": 0.001,\n",
    "                \"explore\": 1000000.,\n",
    "                \"weight_decay\": 0,\n",
    "                \"eps\":0.1,\n",
    "                \"eps_decay\":0.001\n",
    "                }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "seed = config.get(\"seed\", 42)\n",
    "\n",
    "stat_save_path = os.path.join(os.getcwd(),\"saved_stats\")\n",
    "if not os.path.exists(stat_save_path):\n",
    "    os.mkdir(stat_save_path)\n",
    "stat_save_folder  = os.path.join(stat_save_path, \"ddpg_\" + datetime.datetime.now().strftime('%Y%m%d'))\n",
    "if not os.path.exists(stat_save_folder):\n",
    "    os.mkdir(stat_save_folder)\n",
    "\n",
    "agent_save_path = os.path.join(os.getcwd(),\"saved_agents\")\n",
    "if not os.path.exists(agent_save_path):\n",
    "    os.mkdir(agent_save_path)\n",
    "agent_save_folder  = os.path.join(agent_save_path, \"ddpg_\" + datetime.datetime.now().strftime('%Y%m%d'))\n",
    "if not os.path.exists(agent_save_folder):\n",
    "    os.mkdir(agent_save_folder)\n",
    "\n",
    "np.random.seed(seed)\n",
    "window_size = config[\"model\"][\"window_size\"]\n",
    "data_path = config[\"data\"][\"data_path\"] \n",
    "tickers = config[\"data\"][\"tickers\"]\n",
    "time_frame = config[\"data\"][\"time_frame\"]\n",
    "start_date, end_date = config[\"model\"][\"start_date\"] , config[\"model\"][\"end_date\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d5d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50388836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading data for GOOG...\n",
      "INFO:__main__:got data for GOOG...\n",
      "INFO:__main__:loading data for SPY...\n",
      "INFO:__main__:got data for SPY...\n"
     ]
    }
   ],
   "source": [
    "data_source_goog = DataSource(\n",
    "    data_path=data_path,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    time_frame=time_frame,\n",
    "    tickers=[\"GOOG\"],\n",
    "    window_size=window_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "goog = data_source_goog.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ec2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, ticker):\n",
    "    df.set_index(\"date_time\", inplace=True)\n",
    "    # df_train = df.iloc[:int(0.8*len(df)),[1,2,3,4,5,7,8,9]].copy()\n",
    "    # df_test = df.iloc[int(0.8*len(df)):,[1,2,3,4,5,7,8,9]].copy()\n",
    "    df_train = df.iloc[:int(0.8*len(df)),:].copy()\n",
    "    df_test = df.iloc[int(0.8*len(df)):,:].copy()\n",
    "\n",
    "    sig_train = df_train.rolling(30).std()\n",
    "    sig_test = df_test.rolling(30).std()\n",
    "\n",
    "    mu_train = df_train.rolling(30).mean()\n",
    "    mu_test = df_test.rolling(30).mean()\n",
    "\n",
    "    eps = np.finfo(np.float32).eps\n",
    "\n",
    "    df_train_norm = ((df_train - mu_train.shift())/(sig_train + eps)).dropna()\n",
    "    df_test_norm = ((df_test - mu_test.shift())/(sig_test + eps)).dropna()\n",
    "\n",
    "    df_train_norm.columns = [col+\"_norm\" for col in df_train_norm.columns]\n",
    "    df_test_norm.columns = [col+\"_norm\" for col in df_test_norm.columns]\n",
    "\n",
    "    df_train_norm[\"adjclose_\"+ticker] = df_train[\"adjclose_\"+ticker][30:].values\n",
    "    df_train_norm[\"adjopen_\"+ticker] = df_train[\"adjopen_\"+ticker][30:].values\n",
    "    df_test_norm[\"adjclose_\"+ticker] = df_test[\"adjclose_\"+ticker][30:].values\n",
    "    df_test_norm[\"adjopen_\"+ticker] = df_test[\"adjopen_\"+ticker][30:].values\n",
    "\n",
    "    return(df_train, df_test, df_train_norm, df_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_train_norm, df_test_norm = preprocess(goog.copy(), \"GOOG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cba1f64c-a7c1-4279-bb0a-1dd4644072d3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjclose_GOOG</th>\n",
       "      <th>adjopen_GOOG</th>\n",
       "      <th>adjvolume_GOOG</th>\n",
       "      <th>ret_5_GOOG</th>\n",
       "      <th>ret_10_GOOG</th>\n",
       "      <th>rsi_GOOG</th>\n",
       "      <th>macd_GOOG</th>\n",
       "      <th>atr_GOOG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-14 00:00:00+00:00</th>\n",
       "      <td>26.3325</td>\n",
       "      <td>26.6500</td>\n",
       "      <td>23770000</td>\n",
       "      <td>0.033366</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.608101</td>\n",
       "      <td>0.800339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-15 00:00:00+00:00</th>\n",
       "      <td>25.9990</td>\n",
       "      <td>26.2850</td>\n",
       "      <td>33994000</td>\n",
       "      <td>0.033906</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>90.697465</td>\n",
       "      <td>-0.569027</td>\n",
       "      <td>0.798815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-16 00:00:00+00:00</th>\n",
       "      <td>26.0315</td>\n",
       "      <td>26.0695</td>\n",
       "      <td>29624000</td>\n",
       "      <td>0.020832</td>\n",
       "      <td>-0.023175</td>\n",
       "      <td>57.364132</td>\n",
       "      <td>-0.534635</td>\n",
       "      <td>0.778399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-19 00:00:00+00:00</th>\n",
       "      <td>26.4430</td>\n",
       "      <td>25.9850</td>\n",
       "      <td>25486000</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>-0.009756</td>\n",
       "      <td>24.030798</td>\n",
       "      <td>-0.505111</td>\n",
       "      <td>0.766360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-20 00:00:00+00:00</th>\n",
       "      <td>26.4885</td>\n",
       "      <td>26.4870</td>\n",
       "      <td>35598000</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>31.528101</td>\n",
       "      <td>-0.471024</td>\n",
       "      <td>0.770656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cba1f64c-a7c1-4279-bb0a-1dd4644072d3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cba1f64c-a7c1-4279-bb0a-1dd4644072d3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cba1f64c-a7c1-4279-bb0a-1dd4644072d3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                           adjclose_GOOG  adjopen_GOOG  adjvolume_GOOG  \\\n",
       "date_time                                                                \n",
       "2014-05-14 00:00:00+00:00        26.3325       26.6500        23770000   \n",
       "2014-05-15 00:00:00+00:00        25.9990       26.2850        33994000   \n",
       "2014-05-16 00:00:00+00:00        26.0315       26.0695        29624000   \n",
       "2014-05-19 00:00:00+00:00        26.4430       25.9850        25486000   \n",
       "2014-05-20 00:00:00+00:00        26.4885       26.4870        35598000   \n",
       "\n",
       "                           ret_5_GOOG  ret_10_GOOG    rsi_GOOG  macd_GOOG  \\\n",
       "date_time                                                                   \n",
       "2014-05-14 00:00:00+00:00    0.033366     0.010235  100.000000  -0.608101   \n",
       "2014-05-15 00:00:00+00:00    0.033906    -0.002675   90.697465  -0.569027   \n",
       "2014-05-16 00:00:00+00:00    0.020832    -0.023175   57.364132  -0.534635   \n",
       "2014-05-19 00:00:00+00:00   -0.007278    -0.009756   24.030798  -0.505111   \n",
       "2014-05-20 00:00:00+00:00   -0.002166     0.008587   31.528101  -0.471024   \n",
       "\n",
       "                           atr_GOOG  \n",
       "date_time                            \n",
       "2014-05-14 00:00:00+00:00  0.800339  \n",
       "2014-05-15 00:00:00+00:00  0.798815  \n",
       "2014-05-16 00:00:00+00:00  0.778399  \n",
       "2014-05-19 00:00:00+00:00  0.766360  \n",
       "2014-05-20 00:00:00+00:00  0.770656  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64c4d1",
   "metadata": {},
   "source": [
    "## Custom Trading Environment Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3b2fa",
   "metadata": {},
   "source": [
    "An environment with the OpenAI gym interface to simulate market movement and reward generation.\n",
    "\n",
    "The agent moves to the beginning of the next trading day by taking action at each step, and its assets' value change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, window_size, frame_bound, init_cash=100_000, symbol=\"\", IS_DQN=False):\n",
    "        assert df.ndim == 2\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        \n",
    "        self.symbol = symbol\n",
    "        self.IS_DQN = IS_DQN\n",
    "        self.frame_bound = frame_bound\n",
    "        self.window_size = window_size\n",
    "        self.dates = df.index\n",
    "        self.open_prices, self.close_prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size *  self.signal_features.shape[1],)\n",
    "        \n",
    "        # defining Action and State spaces\n",
    "        self.action_space = spaces.Discrete(n=3)\n",
    "        # self.action_space = spaces.Box(low=-1,high=1,shape=(1,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float64)\n",
    "\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.open_prices) - 1\n",
    "        # self._start_tick , self._end_tick = get_start_end_index(self.frame_bound[0],self.frame_bound[1])\n",
    "        self.starting_price = self.open_prices[self._start_tick]\n",
    "        self._done = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self.init_cash = init_cash\n",
    "        self._cash = init_cash\n",
    "        self._position_value = 0\n",
    "        self._total_assets = self._cash + self._position_value\n",
    "        self._init_total_assets = self._total_assets\n",
    "        self._last_trade = 0\n",
    "        self._position_history = None\n",
    "        self._actions_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self, rand_trail=False):\n",
    "        self._done = False\n",
    "        if rand_trail:\n",
    "            self._start_tick , _ = get_start_end_index(self.frame_bound[0], self.frame_bound[1])\n",
    "        else:\n",
    "            self._start_tick = self.frame_bound[0]\n",
    "        self._end_tick = self.frame_bound[1] - 1 \n",
    "        self._current_tick = self._start_tick\n",
    "        self.starting_price = self.open_prices[self._start_tick]\n",
    "        self.curr_open_price = self.open_prices[self._start_tick]\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._cash = self.init_cash\n",
    "        self._position_value = 0\n",
    "        self._total_assets = self._cash + self._position_value\n",
    "        self._init_total_assets = self._total_assets\n",
    "        self._last_trade = 0\n",
    "        self._position_history = (self.window_size * [0]) + [self._position_value]\n",
    "        self._trade_history = (self.window_size * [0]) + [self._last_trade]\n",
    "        self._actions_history = ((1+self.window_size) * [0]) \n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 0.  # unit\n",
    "        self._total_pct_profit = 0\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "        self.curr_open_price = self.open_prices[self._current_tick]\n",
    "\n",
    "        # if self.IS_DQN:\n",
    "        #     action = action-1\n",
    "        action = action-1\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "        if -0.01<action<0.01:\n",
    "            action = np.zeros(1)\n",
    "        action = action.item()\n",
    "        last_day_total_assets = self._total_assets\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._actions_history.append(action)\n",
    "        self._total_reward += step_reward\n",
    "        self._total_profit = self._total_assets - self.init_cash\n",
    "        self._total_pct_profit = self._total_profit/self.init_cash\n",
    "\n",
    "        # self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            date = self.dates[self._current_tick],\n",
    "            total_reward = rnd(self._total_reward),\n",
    "            total_profit = rnd(self._total_profit),\n",
    "            total_profit_percentage = rnd(self._total_pct_profit),\n",
    "            buy_and_hold = rnd((self.curr_open_price/self.starting_price)-1),\n",
    "            daily_price_return =rnd((self.curr_open_price/self.open_prices[self._current_tick-1])-1),\n",
    "            daily_return = rnd((self._total_assets/last_day_total_assets)-1),\n",
    "            total_assets = rnd(self._total_assets),\n",
    "             \n",
    "        )\n",
    "        self._update_history(info)\n",
    "\n",
    "        return observation, step_reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        sig = self.signal_features[(self._current_tick-self.window_size):self._current_tick]\n",
    "        # obs = np.hstack([np.array(self._cash/self.init_cash), np.array(self._position_value/self.init_cash),\n",
    "        #                     sig.reshape(-1)])\n",
    "        return(sig.reshape(-1))\n",
    "\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "\n",
    "        def _plot_position(position, tick):\n",
    "            color = None\n",
    "            if position > 0:\n",
    "                color = 'red'\n",
    "            elif position < 0:\n",
    "                color = 'green'\n",
    "            if color:\n",
    "                plt.scatter(tick, self.prices[tick], color=color)\n",
    "\n",
    "        if self._first_rendering:\n",
    "            self._first_rendering = False\n",
    "            plt.cla()\n",
    "            plt.plot(self.open_prices)\n",
    "            start_position = self._position_history[self._start_tick]\n",
    "            _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "\n",
    "        plt.pause(0.01)\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        window_ticks = np.arange(self._start_tick, self._end_tick)\n",
    "        plt.plot(\n",
    "            pd.to_datetime(self.dates),\n",
    "            self.open_prices,\n",
    "            label=f\"Open Price - {self.symbol}\"\n",
    "            )\n",
    "\n",
    "        short_ticks = []\n",
    "        short_ticks_dates = []\n",
    "        long_ticks = []\n",
    "        long_ticks_dates = []\n",
    "        for i, tick in enumerate(window_ticks):\n",
    "            if self._trade_history[i] < 0:\n",
    "                short_ticks.append(tick)\n",
    "                short_ticks_dates.append(\n",
    "                    self.dates[tick]\n",
    "                )\n",
    "            elif self._trade_history[i] > 0:\n",
    "                long_ticks.append(tick)\n",
    "                long_ticks_dates.append(\n",
    "                    self.dates[tick]\n",
    "                )\n",
    "\n",
    "        plt.plot(\n",
    "            pd.to_datetime(short_ticks_dates),\n",
    "            self.open_prices[short_ticks],\n",
    "            'rv',\n",
    "            markersize=6,\n",
    "            label=\"Sell\"\n",
    "            )\n",
    "        plt.plot(\n",
    "            pd.to_datetime(long_ticks_dates),\n",
    "            self.open_prices[long_ticks],\n",
    "            'g^',\n",
    "            markersize=6,\n",
    "            label=\"Buy\"\n",
    "            )\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def _process_data(self):\n",
    "        close_prices = self.df.loc[:, 'adjclose_'+self.symbol].to_numpy()\n",
    "        open_prices = self.df.loc[:, 'adjopen_'+self.symbol].to_numpy()\n",
    "\n",
    "        open_prices[self.frame_bound[0] - self.window_size]  # validate index (TODO: Improve validation)\n",
    "        # close_prices = close_prices[self.frame_bound[0]-self.window_size:self.frame_bound[1]]\n",
    "        # open_prices = open_prices[self.frame_bound[0]-self.window_size:self.frame_bound[1]]\n",
    "\n",
    "        # diff = np.insert(np.diff(prices), 0, 0)\n",
    "        # signal_features = np.column_stack((prices, diff))\n",
    "        features = ['adjopen_'+self.symbol, 'adjvolume_'+self.symbol,\n",
    "                    'ret_5_'+self.symbol, 'ret_10_'+self.symbol,\n",
    "                    'ret_21_'+self.symbol, 'rsi_'+self.symbol,\n",
    "                    'macd_'+self.symbol,'atr_'+self.symbol]\n",
    "\n",
    "        signal_features = self.df[features].values\n",
    "\n",
    "        return(open_prices, close_prices, signal_features)\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "\n",
    "        trade = True\n",
    "        step_reward = 0\n",
    "        \n",
    "        current_price = self.open_prices[self._current_tick]\n",
    "        last_day_price = self.open_prices[self._current_tick-1]\n",
    "        pct_change = (current_price)/last_day_price\n",
    "\n",
    "        before_position_value = self._position_value\n",
    "        before_total_assets = self._total_assets\n",
    "        self._position_value *= pct_change\n",
    "        self._total_assets = self._cash + self._position_value\n",
    "\n",
    "        if trade:\n",
    "            total_assets = self._total_assets\n",
    "            new_position_value = action * total_assets\n",
    "            position_value_diff = new_position_value - self._position_value\n",
    "\n",
    "            num_assets_to_trade = position_value_diff // current_price\n",
    "\n",
    "            actual_position_value_diff = num_assets_to_trade*current_price\n",
    "            actual_new_position_value = actual_position_value_diff + self._position_value\n",
    "\n",
    "            ## TODO: try different reward functions.\n",
    "            ## TODO: add rewards for commission, etc.\n",
    "\n",
    "            self._position_value = actual_new_position_value\n",
    "            self._cash = total_assets - actual_new_position_value\n",
    "            self._total_assets = self._cash + self._position_value\n",
    "\n",
    "            self._last_trade = actual_position_value_diff\n",
    "            self._trade_history.append(num_assets_to_trade)\n",
    "            self._position_history.append(actual_new_position_value)\n",
    "            self._last_trade_tick = self._current_tick\n",
    "        else:\n",
    "            \n",
    "            self._trade_history.append(0)\n",
    "            self._position_history.append(self._position_value)\n",
    "\n",
    "        # step_reward = 0\n",
    "        # bnh = ((current_price/self.starting_price)-1)\n",
    "        # step_reward += (((self._total_assets - self.init_cash))/self.init_cash)-bnh\n",
    "        # step_reward = (self._total_assets - before_total_assets)\n",
    "        step_reward = ((self._total_assets - before_total_assets)/before_total_assets)\n",
    "\n",
    "        return step_reward\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def max_possible_profit(self):  # trade fees are ignored\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adf269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b2d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2014-02-20 00:00:00+00:00', '2020-11-18 00:00:00+00:00') \n",
      " ('2020-11-19 00:00:00+00:00', '2022-08-01 00:00:00+00:00')\n"
     ]
    }
   ],
   "source": [
    "print((df_ibm_train.index[0], df_ibm_train.index[-1]),\"\\n\",\n",
    "      (df_ibm_test.index[0], df_ibm_test.index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a98efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_maker = lambda: MyTradingEnv(\n",
    "    df=df_train,\n",
    "    window_size=window_size,\n",
    "    frame_bound=(window_size,len(df_train)),\n",
    "    symbol=\"GOOG\"\n",
    "    )\n",
    "# env = DummyVecEnv([env_maker])\n",
    "\n",
    "env = MyTradingEnv(\n",
    "    df=df_train,\n",
    "    window_size=window_size,\n",
    "    frame_bound=(window_size,len(df_train)),\n",
    "    symbol=\"GOOG\"\n",
    "    )\n",
    "\n",
    "test_env = MyTradingEnv(\n",
    "    df=df_test,\n",
    "    window_size=window_size,\n",
    "    frame_bound=(window_size, len(df_test)),\n",
    "    symbol=\"GOOG\"\n",
    "    )\n",
    "\n",
    "# env = MyTradingEnv(df=df_train_norm, window_size=window_size, frame_bound=(window_size, len(df_train_norm)))\n",
    "# test_env = MyTradingEnv(df=df_test_norm, window_size=window_size, frame_bound=(window_size, len(df_test_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80979255",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_index(a,b):\n",
    "        \n",
    "    start_index = np.random.randint(a, b-20)\n",
    "    end_index = np.random.randint(start_index+10, b)\n",
    "\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_env, rounds=500):\n",
    "    '''\n",
    "    Calculates Performance statistics on the test environment over multiple\n",
    "    rounds of interactionwith the test environment.\n",
    "\n",
    "    calculated statistics are:\n",
    "        point estimation (mean)\n",
    "        %95 confidence interval bound\n",
    "        %99 confidence interval bound\n",
    "        3-standard deviation (3sigma) interval\n",
    "        3-standard deviation (3sigma) interval\n",
    "        best 5 percentile\n",
    "        worst 5 percentile\n",
    "        best 20 percentile\n",
    "        best 20 percentile\n",
    "\n",
    "    metrics are:\n",
    "        total_reward\n",
    "        total_profit\n",
    "        total_profit_percentage\n",
    "        buy_and_hold\n",
    "        daily_price_return\n",
    "        daily_return\n",
    "        total_assets\n",
    "        performance metrics: (\n",
    "            Annual return\n",
    "            Cumulative returns\n",
    "            Annual volatility\n",
    "            Sharpe ratio\n",
    "            Calmar ratio\n",
    "            Stability\n",
    "            Max drawdown\n",
    "            Omega ratio\n",
    "            Sortino ratio\n",
    "            Skew\n",
    "            Kurtosis\n",
    "            Tail ratio\n",
    "            Daily value at risk\n",
    "            )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        - model: RL Agent instance (`Agent` class from stablebaseline3 )\n",
    "        - test_env: Trading environment to test on. (`Mytradingenv` class with OpenAI gym interface)\n",
    "        - rounds: number of rounds to fully interact with test environment.\n",
    "            statistics are calculated over this number of runs. (`int`)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        - mean_res: dictionary containing performance statistics of the agent on\n",
    "            the test_env.\n",
    "    '''\n",
    "    res = dict(\n",
    "        date = [],\n",
    "        total_reward = [],\n",
    "        total_profit = [],\n",
    "        total_profit_percentage = [],\n",
    "        buy_and_hold = [],\n",
    "        daily_price_return = [],\n",
    "        daily_return = [],\n",
    "        total_assets = [],\n",
    "        perf_stat = pd.DataFrame(),\n",
    "        bnh_perf_stat = pd.DataFrame()\n",
    "        )\n",
    "    \n",
    "    for itr in tqdm(range(rounds)):\n",
    "        observation = test_env.reset(False)\n",
    "\n",
    "        while True:\n",
    "            action, _states = model.predict(observation)\n",
    "            observation, reward, done, info = test_env.step(action)\n",
    "\n",
    "            # env.render()\n",
    "            if done:\n",
    "                # print(\"info:\", info)\n",
    "                break\n",
    "\n",
    "        for key in test_env.history.keys():\n",
    "            res[key].append(test_env.history[key])\n",
    "\n",
    "        res[\"perf_stat\"] = pd.concat(\n",
    "            [\n",
    "            res[\"perf_stat\"],\n",
    "            ts.perf_stats(np.array(test_env.history['daily_return']))\n",
    "            ],\n",
    "            axis=1)\n",
    "\n",
    "    for key , val in res.items():\n",
    "        if key not in ['date', 'perf_stat']:\n",
    "            res[key] = np.array(val)\n",
    "\n",
    "    mean_res = {}\n",
    "    for k, v in res.items():\n",
    "        if k == 'date':\n",
    "            mean_res[k] = v[0]\n",
    "        elif k == 'perf_stat':\n",
    "\n",
    "            m = v.mean(1)\n",
    "            s = v.std(1)\n",
    "            dof = rounds-1\n",
    "\n",
    "            se = st.sem(v.values, axis=1)\n",
    "            # h = se * st.t.ppf((1 + confidence) / 2., dof)\n",
    "            # lower95, upper95 = (m-s*(t_crit95/np.sqrt(rounds)), m+s*(t_crit95/np.sqrt(rounds)))\n",
    "            # lower99, upper99 = (m-s*(t_crit99/np.sqrt(rounds)), m+s*(t_crit99/np.sqrt(rounds)))\n",
    "            # stats = pd.concat([pd.Series(m),pd.Series(se)],axis=1)\n",
    "            \n",
    "            lower95, upper95 = st.t.interval(alpha=0.95, df=dof, loc=m, scale=se)\n",
    "            lower99, upper99 = st.t.interval(alpha=0.99, df=dof, loc=m, scale=se)\n",
    "\n",
    "            lower95 = pd.Series(lower95)\n",
    "            upper95 = pd.Series(upper95)\n",
    "            lower99 = pd.Series(lower99)\n",
    "            upper99 = pd.Series(upper99)\n",
    "            \n",
    "            lower95.index = v.index\n",
    "            upper95.index = v.index\n",
    "            lower99.index = v.index\n",
    "            upper99.index = v.index\n",
    "\n",
    "            lower_3s = m - 1.5*s\n",
    "            upper_3s = m + 1.5*s\n",
    "\n",
    "            # ===============================\n",
    "            \n",
    "            best5pct = np.quantile(v.values, 0.95, axis=1)\n",
    "            worst5pct = np.quantile(v.values, 0.05, axis=1)\n",
    "            best20 = np.quantile(v.values, 0.8, axis=1)\n",
    "            worst20 = np.quantile(v.values, 0.2, axis=1)\n",
    "\n",
    "            best5pct = pd.Series(best5pct)\n",
    "            worst5pct = pd.Series(worst5pct)\n",
    "            best20 = pd.Series(best20)\n",
    "            worst20 = pd.Series(worst20)\n",
    "\n",
    "            best5pct.index = v.index\n",
    "            worst5pct.index = v.index\n",
    "            best20.index = v.index\n",
    "            worst20.index = v.index\n",
    "\n",
    "            # ===============================\n",
    "\n",
    "            mean_res[k] = pd.concat([m ,\n",
    "                                    lower95, upper95,\n",
    "                                    lower99, upper99,\n",
    "                                    lower_3s, upper_3s,\n",
    "                                    best5pct, worst5pct,\n",
    "                                    best20, worst20\n",
    "                                    ], axis=1\n",
    "                                    )\n",
    "            \n",
    "            mean_res[k].columns = [\"point_est (mean)\",\n",
    "                                   \"%95 conf. lower bound\", \"%95 conf. upper bound\",\n",
    "                                   \"%99 conf. lower bound\", \"%99 conf. upper bound\",\n",
    "                                   \"3sigma lower\", \"3sigma upper\",\n",
    "                                   \"best_5_pctile\", \"worst_5_pctile\",\n",
    "                                   \"best_20_pctile\", \"best_20_pctile\"\n",
    "                                   ]\n",
    "        \n",
    "        elif k==\"bnh_perf_stat\":\n",
    "            mean_res[k] = ts.perf_stats(\n",
    "                test_env.df[\"adjopen_\"+test_env.symbol][test_env.frame_bound[0]:test_env.frame_bound[1]].pct_change().fillna(0).values\n",
    "                )\n",
    "        elif k in [\"buy_and_hold\", \"daily_price_return\"]:\n",
    "            mean_res[k] = v.mean(0)\n",
    "        else:\n",
    "            mean_res[k+\"_point\"] = v.mean(0)\n",
    "            m = v.mean(0)\n",
    "            s = v.std(0)\n",
    "            dof = rounds-1\n",
    "\n",
    "            # t_crit95 = np.abs(t.ppf((1-0.95)/2,dof))\n",
    "            # t_crit99 = np.abs(t.ppf((1-0.99)/2,dof))\n",
    "\n",
    "            # lower95, upper95 = (m-s*(t_crit95/np.sqrt(rounds)), m+s*(t_crit95/np.sqrt(rounds)))\n",
    "            # lower99, upper99 = (m-s*(t_crit99/np.sqrt(rounds)), m+s*(t_crit99/np.sqrt(rounds)))\n",
    "            se = st.sem(v, axis=0)\n",
    "            lower95, upper95 = st.t.interval(alpha=0.95, df=dof, loc=m, scale=se)\n",
    "            lower99, upper99 = st.t.interval(alpha=0.99, df=dof, loc=m, scale=se)\n",
    "\n",
    "            mean_res[k+\"_lower95\"] = lower95\n",
    "            mean_res[k+\"_upper95\"] = upper95\n",
    "\n",
    "            mean_res[k+\"_lower99\"] = lower99\n",
    "            mean_res[k+\"_upper99\"] = upper99\n",
    "\n",
    "            mean_res[k+\"_min\"] = v.min(0)\n",
    "            mean_res[k+\"_max\"] = v.max(0)\n",
    "\n",
    "            mean_res[k+\"_best5pctile\"] = np.quantile(v, 0.95, axis=0)\n",
    "            mean_res[k+\"_worst5pctile\"] = np.quantile(v, 0.05, axis=0)\n",
    "\n",
    "            mean_res[k+\"_best20pctile\"] = np.quantile(v, 0.8, axis=0)\n",
    "            mean_res[k+\"_worst20\"] = np.quantile(v, 0.2, axis=0)\n",
    "\n",
    "            mean_res[k+\"_lower3S\"] = m - 1.5*s\n",
    "            mean_res[k+\"_upper3S\"] = m + 1.5*s\n",
    "     \n",
    "    return(mean_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_result(\n",
    "        result_dict,\n",
    "        model_name,\n",
    "        symbol,\n",
    "        split=\"Test\",\n",
    "        plot_95_conf=True,\n",
    "        plot_99_conf=False,\n",
    "        plot_6s=True,\n",
    "        plot_minmax=False,\n",
    "        plot_bestworst20=False,\n",
    "        plot_bestworst5=False,\n",
    "        ):\n",
    "    '''\n",
    "    Plots the performance metrics and statistics from the Agent test results\n",
    "    '''\n",
    "    plt.style.use(\"seaborn\")\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.title(f\"{model_name} {split} Performance - {symbol}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.title(f\"{model_name} {split} Performance - {symbol}\")\n",
    "    # plt.plot(x,np.array(test_env.history['buy_and_hold'])*test_env.init_cash)\n",
    "    plt.plot(pd.to_datetime(result_dict['date']), result_dict['buy_and_hold'], label=\"Buy and Hold\")\n",
    "    plt.plot(pd.to_datetime(result_dict['date']), result_dict['total_profit_percentage_point'],label=model_name,color=\"r\")\n",
    "\n",
    "    if plot_95_conf:\n",
    "        plt.fill_between(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_percentage_upper95'],\n",
    "            result_dict['total_profit_percentage_lower95'],\n",
    "            label=\"95% Conf. Int.\",\n",
    "            alpha=0.8\n",
    "            )\n",
    "\n",
    "    if plot_99_conf:\n",
    "        plt.fill_between(\n",
    "            range(len(result_dict['date'])),\n",
    "            result_dict['total_profit_percentage_upper99'],\n",
    "            result_dict['total_profit_percentage_lower99'],\n",
    "            label=\"99% Conf. Int.\",\n",
    "            alpha=0.6\n",
    "            )\n",
    "\n",
    "    if plot_6s:\n",
    "        plt.fill_between(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_percentage_upper3S'],\n",
    "            result_dict['total_profit_percentage_lower3S'],\n",
    "            label=\"3 Sigma\",\n",
    "            alpha=0.65\n",
    "            )\n",
    "    \n",
    "    if plot_minmax:\n",
    "        plt.fill_between(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_percentage_max'],\n",
    "            result_dict['total_profit_percentage_min'],\n",
    "            label=\"Min/Max\",\n",
    "            alpha=0.3\n",
    "            )\n",
    "    \n",
    "    if plot_bestworst20:\n",
    "        plt.plot(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_best20pctile'],\n",
    "            label=\"Best 20th percentile\",\n",
    "            alpha=0.5\n",
    "            )\n",
    "        plt.plot(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_worst20pctile'],\n",
    "            label=\"Worst 20th percentile\",\n",
    "            alpha=0.5\n",
    "            )\n",
    "        # plt.fill_between(\n",
    "        #     pd.to_datetime(result_dict['date']),\n",
    "        #     result_dict['total_profit_best20pctile'],\n",
    "        #     result_dict['total_profit_worst20pctile'],\n",
    "        #     label=\"Best/Worst 20 percentile\",\n",
    "        #     alpha=0.5\n",
    "        #     )\n",
    "\n",
    "    if plot_bestworst5:\n",
    "        plt.plot(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_best5pctile'],\n",
    "            label=\"Best 5th percentile\",\n",
    "            alpha=0.5\n",
    "            )\n",
    "        plt.plot(\n",
    "            pd.to_datetime(result_dict['date']),\n",
    "            result_dict['total_profit_worst5pctile'],\n",
    "            label=\"Worst 5th percentile\",\n",
    "            alpha=0.5\n",
    "            )\n",
    "        # plt.fill_between(\n",
    "        #     pd.to_datetime(result_dict['date']),\n",
    "        #     result_dict['total_profit_best5pctile'],\n",
    "        #     result_dict['total_profit_worst5pctile'],\n",
    "        #     label=\"Best/Worst 5 percentile\",\n",
    "        #     alpha=0.4\n",
    "        #     )\n",
    "        \n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0a7a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "306fcd27",
   "metadata": {},
   "source": [
    "-------\n",
    "## PPO Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79453ce8",
   "metadata": {},
   "source": [
    "### Agent setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom network for policy and value function.\n",
    "    It receives as input the features extracted by the feature extractor.\n",
    "\n",
    "    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "    :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 64,\n",
    "        last_layer_dim_vf: int = 64,\n",
    "    ):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # Save output dimensions, used to create the distributions\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # Policy network\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.07),\n",
    "            nn.Linear(256, last_layer_dim_pi),\n",
    "            nn.BatchNorm1d(last_layer_dim_pi),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.07)\n",
    "        )\n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.07),\n",
    "            nn.Linear(256, last_layer_dim_pi),\n",
    "            nn.BatchNorm1d(last_layer_dim_pi),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.07)\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: gym.spaces.Space,\n",
    "        action_space: gym.spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "        activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            net_arch,\n",
    "            activation_fn,\n",
    "            # Pass remaining arguments to base class\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Disable orthogonal initialization\n",
    "        self.ortho_init = False\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebfaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    }
   ],
   "source": [
    "ppo_agent = PPO(\n",
    "    CustomActorCriticPolicy,\n",
    "    env,\n",
    "    learning_rate=0.0001,\n",
    "    n_steps=1024,\n",
    "    batch_size=128,\n",
    "    n_epochs=15,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    clip_range_vf=None,\n",
    "    normalize_advantage=True,\n",
    "    verbose=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
